{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "courses_prices = pd.read_csv('./Data/course_prices.csv')\n",
    "courses = pd.read_csv('./Data/Coursera_courses.csv')\n",
    "users = pd.read_csv('./Data/Coursera_reviews.csv')\n",
    "courses_metadata = pd.read_csv('./Data/CourseraDataset-Unclean.csv')\n",
    "job_skills = pd.read_csv('./Data/job_skills.csv')\n",
    "job_metadata = pd.read_csv('./Data/linkedin_job_postings.csv')\n",
    "course_desc_1 = pd.read_csv('./Data/coursera_course_dataset_v3.csv')\n",
    "course_desc_2 = pd.read_csv('./Data/coursera_courses (2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicate Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_metadata.rename(columns={'Course Title': 'name', 'Rating': 'Overall Ratings', 'Review': 'Num of Reviews', 'Offered By': 'institution'}, inplace = True)\n",
    "courses_metadata.drop_duplicates(subset=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicate Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.drop_duplicates(subset=['reviews', 'reviewers', 'course_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(job_skills.isnull().sum())\n",
    "#print(courses.isnull().sum())\n",
    "#print(users.isnull().sum())\n",
    "job_skills = job_skills.dropna(subset=['job_skills'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "users['reviews'] = users['reviews'].astype(str)\n",
    "\n",
    "# Remove rows where 'reviews' only contains punctuation\n",
    "users = users[users['reviews'].str.contains(r'\\w', regex=True)]\n",
    "\n",
    "# Remove rows where 'reviews' contains emojis\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "users = users[~users['reviews'].apply(lambda x: bool(emoji_pattern.search(x)))]\n",
    "\n",
    "# Remove rows where 'reviews' contains emails or websites\n",
    "users = users[~users['reviews'].str.contains(r'\\S*@\\S*\\s?|http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', regex=True)]\n",
    "users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Courses with Users by course_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(users, courses, on=\"course_id\", how=\"inner\")\n",
    "#temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Courses with additional dataset to get missing descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### course_desc_1\n",
    "course_desc_1 = course_desc_1.loc[(course_desc_1['course_description'].notna())]\n",
    "course_desc_1 = course_desc_1[['Title', 'Skills', 'course_description']]\n",
    "\n",
    "### course_desc_2\n",
    "course_desc_2 = course_desc_2.loc[(course_desc_2['course_description'].notna())]\n",
    "course_desc_2 = course_desc_2[['course_title', 'course_skills', 'course_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_temp = pd.merge(courses_metadata, course_desc_1, left_on=\"name\", right_on=\"Title\", how=\"left\")\n",
    "description_temp = description_temp.drop(columns=['Title'])\n",
    "description_temp = pd.merge(description_temp, course_desc_2, left_on=\"name\", right_on=\"course_title\", how=\"left\")\n",
    "description_temp = description_temp.drop(columns=['course_title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_description(row):\n",
    "\n",
    "    x = row['What you will learn'] if pd.notna(row['What you will learn']) else ''\n",
    "    y = row['course_description_y'] if pd.notna(row['course_description_y']) else ''\n",
    "    z = row['course_description_x'] if pd.notna(row['course_description_x']) else ''\n",
    "    \n",
    "    if x == '' and y == '' and z == '':\n",
    "        return ''\n",
    "    if x == y:\n",
    "        return x + ' ' + '\\n' + ' ' + z\n",
    "    elif x == z:\n",
    "        return x + ' ' + '\\n' + ' ' + y\n",
    "    elif y == z:\n",
    "        return y + ' ' + '\\n' + ' ' + x\n",
    "    else:\n",
    "        return x + ' ' + '\\n' + ' ' + y + ' ' + '\\n' + ' ' + z\n",
    "\n",
    "description_temp['description'] = description_temp.apply(merge_description, axis=1)\n",
    "description_temp = description_temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_skills(row):\n",
    "\n",
    "    x = row['Skill gain'] if pd.notna(row['Skill gain']) else ''\n",
    "    y = row['Skills'] if pd.notna(row['Skills']) else ''\n",
    "    z = row['course_skills'] if pd.notna(row['course_skills']) else ''\n",
    "    \n",
    "    if x == '' and y == '' and z == '':\n",
    "        return ''\n",
    "    if x == y:\n",
    "        return x + ' , ' + z\n",
    "    elif x == z:\n",
    "        return x + ' , ' + y\n",
    "    elif y == z:\n",
    "        return z + ' , ' + x\n",
    "    else:\n",
    "        return x + ' , ' + y + ' , ' + z\n",
    "    \n",
    "description_temp['skills'] = description_temp.apply(merge_skills, axis=1)\n",
    "description_temp = description_temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_temp = description_temp.drop(columns=['What you will learn', 'course_description_x', 'course_description_y', 'Skill gain', 'Skills', 'course_skills'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-ASCII and non-English rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    # Normalize text: lowercase and strip leading/trailing whitespace\n",
    "    text = text.lower().strip()\n",
    "    # Remove single and double quotation marks\n",
    "    text = re.sub(r'[\\[\\]\\'\"]', '', text)\n",
    "    # Remove parentheses\n",
    "    text = re.sub(r'[()]', '', text)\n",
    "    # Replace special characters and bullet points with empty string\n",
    "    text = re.sub(r'[\\t\\n\\r]+', '', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "temp['reviewers'] = temp['reviewers'].apply(lambda x: x[3:])\n",
    "temp['reviewers'] = temp['reviewers'].apply(clean_text)\n",
    "temp['name'] = temp['name'].apply(clean_text)\n",
    "temp['institution'] = temp['institution'].apply(clean_text)\n",
    "temp['reviews'] = temp['reviews'].apply(lambda x: str(x))\n",
    "temp['reviews'] = temp['reviews'].apply(clean_text)\n",
    "temp['course_id'] = temp['course_id'].apply(clean_text)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess course prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courses_prices['name'] = courses_prices['name'].apply(clean_text)\n",
    "# courses_prices['institution'] = courses_prices['institution'].apply(clean_text)\n",
    "# courses_prices = courses_prices[courses_prices['is_english_name']]\n",
    "# courses_prices.drop(columns=['is_english_name'], inplace=True)\n",
    "# courses_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess courses metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_temp['skills'] = description_temp['skills'].apply(clean_text)\n",
    "description_temp['Instructor'] = description_temp['Instructor'].apply(clean_text)\n",
    "description_temp['institution'] = description_temp['institution'].apply(clean_text)\n",
    "description_temp['Level'].fillna('None', inplace=True)\n",
    "description_temp['name'] = description_temp['name'].apply(clean_text) \n",
    "description_temp['Duration'] = description_temp['Duration'].astype(str).str.extract('(\\d+)').fillna(0).astype(int)\n",
    "description_temp['Num of Reviews'] = description_temp['Num of Reviews'].astype(str).str.extract('(\\d+)').fillna(0).astype(int)\n",
    "description_temp = description_temp[description_temp['skills'] != '']\n",
    "description_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out empty description rows\n",
    "description_temp = description_temp[description_temp['description'].str.strip() != '']\n",
    "\n",
    "# Filter out skills rows with just \",\"\n",
    "description_temp = description_temp[~description_temp['skills'].str.strip().eq(',')]\n",
    "\n",
    "# Reset the index\n",
    "description_temp = description_temp.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_metadata['job_title'] = job_metadata['job_title'].apply(clean_text)\n",
    "job_skills['job_skills'] = job_skills['job_skills'].apply(lambda x: str(x)).apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Additional Metadata with Temp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_data = pd.merge(temp, description_temp, on=[\"name\", \"institution\"], how=\"inner\")\n",
    "\n",
    "courses_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique courses left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_courses = courses_data.drop_duplicates(subset='name')\n",
    "unique_courses = unique_courses.shape[0]\n",
    "print(f\"Data points: {courses_data.shape[0]}\")\n",
    "print(f\"Unique courses: {unique_courses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dates to Numerical Dates and Sort by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numerical_date(text_date):\n",
    "    actual_date = datetime.strptime(text_date, \"%b %d, %Y\")\n",
    "    return actual_date.year, actual_date.month, actual_date.day\n",
    "\n",
    "courses_data[['year', 'month', 'day']] = courses_data['date_reviews'].apply(lambda x: pd.Series(convert_to_numerical_date(x)))\n",
    "courses_data['date'] = pd.to_datetime(courses_data[['year', 'month', 'day']])\n",
    "courses_data = courses_data.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Essential Columns in Courses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses = courses_data[['reviews', 'reviewers', 'rating', 'name', 'institution', 'Overall Ratings', 'Level', 'Duration', 'Num of Reviews', 'skills', 'Instructor', 'description', 'date']]\n",
    "# final_courses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_courses.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Datasets regarding Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_data = pd.merge(job_skills, job_metadata, on=\"job_link\", how=\"inner\")\n",
    "#jobs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Essential Columns in Jobs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs = jobs_data[['job_skills', 'job_title', 'search_position', 'job_level']]\n",
    "final_jobs.head()\n",
    "unique_values = final_jobs['search_position'].unique()\n",
    "print(unique_values)\n",
    "# print(unique_values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demean Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_average_rating = final_courses.groupby('reviewers')['rating'].transform('mean')\n",
    "final_courses['Demeaned Rating'] = final_courses['rating'] - reviewer_average_rating \n",
    "# final_courses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Price Column to Courses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_courses = pd.merge(final_courses, courses_prices, on=['institution', 'name'], how='inner')\n",
    "# # print(final_courses.isnull().sum())\n",
    "# # print(final_courses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty Reviewers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses = final_courses[final_courses['reviewers'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Popularity to Courses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses['Popularity'] = final_courses['Overall Ratings'] * final_courses['Num of Reviews']\n",
    "# final_courses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove users with less than 3 interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_counts = final_courses['reviewers'].value_counts()\n",
    "reviewers_to_keep = reviewer_counts[reviewer_counts >= 3].index\n",
    "final_courses = final_courses[final_courses['reviewers'].isin(reviewers_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of datapoints: \", final_courses.shape)\n",
    "print(\"Count of Unique Reviewers: \", final_courses['reviewers'].nunique())\n",
    "print(\"Count of Unique Courses: \", final_courses['name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Number of Ratings given by each Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_reviewers = final_courses.groupby('reviewers').size().reset_index(name='count_of_reviews')\n",
    "\n",
    "bin_interval = 200\n",
    "bin_edges = np.arange(0, unique_reviewers['count_of_reviews'].max() + bin_interval, bin_interval)\n",
    "\n",
    "ax = sns.histplot(data=unique_reviewers, x='count_of_reviews', bins=bin_edges, kde=True, edgecolor='black', stat='count')\n",
    "\n",
    "for bin in ax.patches:\n",
    "    if bin.get_height() > 0:\n",
    "        ax.annotate(format(bin.get_height(), '.0f'), \n",
    "                    (bin.get_x() + bin.get_width() / 2., bin.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 5), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "plt.xlabel('Number of Reviews')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Number of Ratings given by each Reviewer')\n",
    "plt.xlim(0, 1400)\n",
    "plt.ylim(0, 25000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Number of Reviews > 600 and Handle it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_review_count = unique_reviewers[unique_reviewers['count_of_reviews'] > 600]\n",
    "print(high_review_count)\n",
    "unique_reviewers = unique_reviewers[unique_reviewers['count_of_reviews'] < 600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Reviewers who have > 600 Number of Reviews from final_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses = final_courses[~final_courses['reviewers'].isin(high_review_count['reviewers'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot New Histogram of Number of Ratings given by each Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_interval = 25\n",
    "bin_edges = np.arange(0, unique_reviewers['count_of_reviews'].max() + bin_interval, bin_interval)\n",
    "\n",
    "ax = sns.histplot(data=unique_reviewers, x='count_of_reviews', bins=bin_edges, kde=True, edgecolor='black', stat='count')\n",
    "\n",
    "for bin in ax.patches:\n",
    "    if bin.get_height() > 0:\n",
    "        ax.annotate(format(bin.get_height(), '.0f'), \n",
    "                    (bin.get_x() + bin.get_width() / 2., bin.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 5), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "plt.xlabel('Number of Reviews')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('New Histogram of Number of Ratings given by each Reviewer')\n",
    "plt.xlim(0, 175)\n",
    "plt.ylim(0, 25000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of datapoints: \", final_courses.shape)\n",
    "print(\"Count of Unique Reviewers: \", final_courses['reviewers'].nunique())\n",
    "print(\"Count of Unique Courses: \", final_courses['name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Popularity of each Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_courses = final_courses.drop_duplicates(subset=['institution', 'name'])\n",
    "\n",
    "bin_interval = 500\n",
    "bin_edges = np.arange(0, grouped_courses['Popularity'].max() + bin_interval, bin_interval)\n",
    "\n",
    "ax = sns.histplot(data=grouped_courses, x='Popularity', bins=bin_edges, kde=True, edgecolor='black', stat='count')\n",
    "\n",
    "for bin in ax.patches:\n",
    "    if bin.get_height() > 0:\n",
    "        ax.annotate(format(bin.get_height(), '.0f'), \n",
    "                    (bin.get_x() + bin.get_width() / 2., bin.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 5), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Popularity of each Course')\n",
    "plt.xlim(0, 5000)\n",
    "plt.ylim(0, 200)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Count of Ratings given for each Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_courses = final_courses.drop_duplicates(subset=['institution', 'name'])\n",
    "\n",
    "bin_interval = 100\n",
    "bin_edges = np.arange(0, grouped_courses['Num of Reviews'].max() + bin_interval, bin_interval)\n",
    "\n",
    "ax = sns.histplot(data=grouped_courses, x='Num of Reviews', bins=bin_edges, kde=True, edgecolor='black', stat='count')\n",
    "\n",
    "for bin in ax.patches:\n",
    "    if bin.get_height() > 0:\n",
    "        ax.annotate(format(bin.get_height(), '.0f'), \n",
    "                    (bin.get_x() + bin.get_width() / 2., bin.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 5), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Number of Ratings for each Course')\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(0, 210)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Overall Ratings of each Course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_courses = final_courses.drop_duplicates(subset=['institution', 'name'])\n",
    "\n",
    "bin_interval = 1\n",
    "bin_edges = np.arange(0, grouped_courses['Overall Ratings'].max() + bin_interval, bin_interval)\n",
    "\n",
    "ax = sns.histplot(data=grouped_courses, x='Overall Ratings', bins=bin_edges, kde=True, edgecolor='black', stat='count')\n",
    "\n",
    "for bin in ax.patches:\n",
    "    if bin.get_height() > 0:\n",
    "        ax.annotate(format(bin.get_height(), '.0f'), \n",
    "                    (bin.get_x() + bin.get_width() / 2., bin.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 5), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "plt.xlabel('Overall Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Overall Ratings of each Course')\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Ratings given by Reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_interval = 1\n",
    "bin_edges = np.arange(0, final_courses['rating'].max() + bin_interval, bin_interval)\n",
    "\n",
    "ax = sns.histplot(data=final_courses, x='rating', bins=bin_edges, kde=True, edgecolor='black', stat='count')\n",
    "\n",
    "for bin in ax.patches:\n",
    "    if bin.get_height() > 0:\n",
    "        ax.annotate(format(bin.get_height(), '.0f'), \n",
    "                    (bin.get_x() + bin.get_width() / 2., bin.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 5), \n",
    "                    textcoords = 'offset points')\n",
    "    \n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Ratings given by each Reviewers')\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 130000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "1. Histogram of Overall Ratings for each Course and Histogram of Ratings given by each Reviewer is left skewed, implying that reviewers usually leave positive ratings. \n",
    "2. Histogram of Number of Ratings of each Course is right skewed, implying the possibility that not many reviewers would leave ratings. \n",
    "\n",
    "Overall, reviewers who leave a rating gave it a high score. There is a possibility that reviewers who are unhappy tend to not leave a rating. \n",
    "\n",
    "### Implications\n",
    "1. It is hard to decipher what reviewers do not like since we do not have data regarding what they gave bad ratings for. \n",
    "\n",
    "### Current Solution\n",
    "1. Use a demeaned rating where a demeaned rating > 0 implies that reviewers \"like\" the course while a demeaned rating <0 implies that reviewers \"less like\" the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_courses.to_csv('final_courses.csv', index=False)\n",
    "final_jobs.to_csv('final_jobs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
